# -*- coding: utf-8 -*-
"""IA projeto final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19-1bhOmWWsR-p8p9KQxen1pT7XW2-JxS
"""

#Montagem do drive
from google.colab import drive
drive.mount('/content/drive/')

#Importando o dataset do drive
import pandas as pd
from sklearn.metrics import accuracy_score
import numpy as np
dataset = pd.read_csv("/content/drive/My Drive/app/Admission_Predict_Ver1.1.csv")

# ALUNOS
# Jesus Dourado de Albuquerque
# Danilo Souza Frazão
# SOBRE O DATASET
# ----------------
# This dataset is inspired by the UCLA Graduate Dataset
# The dataset is owned by Mohan S Acharya.
# A Comparison of Regression Models for Prediction of Graduate Admissions
# IEEE International Conference on Computational Intelligence in Data Science 2019
# Please cite the following if you are interested in using the dataset : 
#      Mohan S Acharya
#      Asfia Armaan, 
#      Aneeta S Antony

# Preparacao das variáveis do dataset
X = dataset.loc[:,'GRE Score':'Research']
Y = dataset.loc[:,'Chance of Admit ']
#print Y

# Dividindo o dataset
from sklearn import model_selection
semente = 17
array = dataset.values
tam = 0.90
X = array[:,1:8]
Y = array[:,8]
X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=tam, random_state=semente)

print X_train
print len(X_train)
print Y_train

# Prepare os registros de teste
X_test = [
          [327,113,4,4.5,4.5,9.04,0],
          [312,103,4,4,5,8.43,0],
          [330,120,5,4.5,5,9.56,1],
          [337,117,5,5,5,9.87,1],
          [332,108,5,4.5,4,9.02,1],
          [301,99,3,2.5,2,8.45,1],
          [300,95,2,3,1.5,8.22,1],
          [298,101,4,2.5,4.5,7.69,1],
          [297,99,4,3,3.5,7.81,0],
          [307,105,2,2.5,4.5,8.12,1]
         ]
chance = [0.84, 0.73, 0.93, 0.96, 0.87, 0.68, 0.62, 0.53, 0.54, 0.67]

# Convertendo a classe de predição de float para string
y = np.array(Y)
y_string = ["%.2f" % x for x in y]

# Utilizando o KNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()

knn.fit(X, y_string)

predicao_knn = knn.predict(X_train)
print "Resultado da predicao utilizando KNN:"
print predicao_knn

# Utilizando o NaiveBayes
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()

# gerar modelo de aprendizgem
nb.fit(X, y_string)

# Predizendo os testes
predicao_nb = nb.predict(X_train)
print "Resultado da predicao utilizando NaiveBayes:"
print(predicao_nb)

#Utilizando Regressão Linear
from sklearn.linear_model import LinearRegression
model = LinearRegression()

#Gerando modelo de aprendizagem
model.fit(X, Y)

#Predizendo os testes
predicao_rl = model.predict(X_train)
print "Resultado da predicao utilizando Regressão: "
print (predicao_rl)

# Plotando o gráfico dos 3 modelos
import matplotlib.pyplot as plt
import numpy as np

# Tratando alguns dados
predicao_knn = predicao_knn.astype(np.float)
predicao_nb = predicao_nb.astype(np.float)

# Tamanho do gráfico
plt.figure(figsize=(15,8))

# Definindo o eixo x
x = np.array(range(len(predicao_rl)))

# Plotando os modelos preditidos
plt.plot(x, predicao_rl, 'k--', label="Regressao Linear", color='blue')
plt.plot(x, predicao_knn, 'k--', label="K NearestNeighbour", color='red')
plt.plot(x, predicao_nb, 'k--', label="Naive Bayes", color='green')
plt.plot(x, Y_train, 'k-', label="Real", color='black')  # linha tracejada azulp

# Configurando o gráfico
plt.axis([-0.5, len(predicao_rl) - 0.5, 0, 1])
plt.legend()
plt.grid(True)
plt.xlabel(str(len(predicao_knn)) + " Instancias")
plt.ylabel("Predicoes")

plt.show()

plt.figure(figsize=(15,4))
plt.plot(x, predicao_nb, 'k--', label="Naive Bayes", color='green')
plt.plot(x, Y_train, 'k-', label="Real", color='black')  # linha tracejada azul
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(15,4))
plt.plot(x, Y_train, 'k-', label="Real", color='black')  # linha tracejada azulp
plt.plot(x, predicao_knn, 'k--', label="K NearestNeighbour", color='red')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(15,4))
plt.plot(x, predicao_rl, 'k--', label="Regressao Linear", color='blue')
plt.plot(x, Y_train, 'k-', label="Real", color='black')  # linha tracejada azul
plt.legend()
plt.grid(True)
plt.show()

# Calculando a precisão das predições em relação aos valores reais

# Total de predições dos valores reais
soma_chance = 0
soma_knn = 0
soma_nb = 0
soma_rl = 0
ix = 0
for i in Y_train:
  # Para Predição Linear
  if(i > predicao_rl[ix]):
    soma_rl = soma_rl + predicao_rl[ix] / i
  else:
    soma_rl = soma_rl + i / predicao_rl[ix]

  # Para K Nearest Neighbour
  if(i > predicao_knn[ix]):
    soma_knn = soma_knn + predicao_knn[ix] / i
  else:
    soma_knn = soma_knn + i / predicao_knn[ix]

  if(i > predicao_nb[ix]):
    soma_nb = soma_nb + predicao_nb[ix] / i
  else:
    soma_nb = soma_nb + i / predicao_nb[ix]

  ix = ix + 1

soma_rl = soma_rl * 100 / len(predicao_rl)
soma_knn = soma_knn * 100 / len(predicao_knn)
soma_nb = soma_nb * 100 / len(predicao_nb)

# Resultado das acurácias

print ("Acuracia de Regressao Linear:      %.2f" % soma_rl + "%")
print ("Acuracia de Naive Bayes:           %.2f" % soma_nb + "%")
print ("Acuracia de K Nearest Neighbour:   %.2f" % soma_knn + "%")

# Recebendo informações do usuário

usuario = []

# GRE Score
gre = float(input('Nota geral do Enem: '))
gre = (gre * 0.08) + 260
usuario.append(gre)

# TOEFL Score
toefl = float(input('Nota de ingles do Enem: '))
toefl *= 0.12
usuario.append(toefl)

# University Rating
uniRat = float(input('Nota da faculdade no ENADE: '))
usuario.append(uniRat)

# SOP
sop = float(input('Nota de redacao do Enem: '))
sop *= 0.005
usuario.append(sop)

# LOR
lor = float(input('Nota da Carta de Recomendacao: '))
lor *= 0.005
usuario.append(lor)

# CGPA
cgpa = float(input('Coeficiente no Ensino Medio: '))
usuario.append(cgpa)

# Research
reser = float(input('Tem experiencia em pesquisa? '))
usuario.append(reser)

# Preparando o caso de teste
teste_usuario = []
teste_usuario.append(usuario)

# Predicao utilizando Regressao Linear
predicao_usuario = model.predict(teste_usuario)
print ("Chance de Admissao: %.2f" % (predicao_usuario * 100) + "%")